{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ef7c2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aa8f35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e6c724",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c71feeae",
   "metadata": {},
   "source": [
    "# Original function\n",
    "\n",
    "- 깃헙에 있는 함수를 그대로 가져온 것입니다.\n",
    "- 이 스터디 덕분에 rotary position embedding에 대해서도 공부하게 되었는데, 그게 어떻게 구현되었는지 살펴보고자 했습니다.\n",
    "- 원본의 input, output 뿐만 아니라 중간 data shape와 같은 흐름 또한 확인하고자했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fdc81be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _rotate_half(x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    change sign so the last dimension becomes [-odd, +even]\n",
    "    \"\"\"\n",
    "    x = x.view(x.shape[:-1] + torch.Size((2, x.shape[-1] // 2)))\n",
    "    x1, x2 = x.unbind(dim=-2)\n",
    "    return torch.cat((-x2, x1), dim=-1)\n",
    "\n",
    "\n",
    "def apply_rotary_pos_emb_pytorch(\n",
    "    t: torch.Tensor,\n",
    "    freqs: torch.Tensor,\n",
    "    tensor_format: str = \"sbhd\",\n",
    "    fused: bool = False,\n",
    "    cu_seqlens: Union[torch.Tensor, None] = None,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Apply rotary positional embedding tensor to the input tensor.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    t: torch.Tensor\n",
    "        Input tensor of shape `[s, b, h, d]`, `[s, b, h, d]` or `[t, h, d]`, on which\n",
    "        rotary positional embedding will be applied.\n",
    "    freqs: torch.Tensor\n",
    "        Rotary positional embedding tensor of shape `[s2, 1, 1, d2]` and dtype 'float',\n",
    "        with `s2 >= s` and `d2 <= d`.\n",
    "    fused: bool, default = False\n",
    "        Whether to use a fused applying RoPE implementation.\n",
    "    tensor_format: {'sbhd', 'bshd', 'thd'}, default = 'sbhd'\n",
    "        is `bshd` if `t` is of shape `[bs, seq, ...]`, or `sbhd` if `t` is\n",
    "        of shape `[seq, bs, ...]`. 'thd' is only supported when `fused` is True.\n",
    "    cu_seqlens: torch.Tensor, default = None.\n",
    "        Cumulative sum of sequence lengths in a batch for `t`, with shape [b + 1] and\n",
    "        dtype torch.int32. Only valid when `tensor_format` is 'thd'.\n",
    "    \"\"\"\n",
    "    if fused:\n",
    "        assert (\n",
    "            tensor_format != \"thd\" or cu_seqlens is not None\n",
    "        ), \"cu_seqlens must not be None when tensor_format is 'thd'.\"\n",
    "        return FusedRoPEFunc.apply(t, freqs, tensor_format, cu_seqlens)\n",
    "\n",
    "    assert tensor_format in (\"sbhd\", \"bshd\"), (\n",
    "        \"Only formats `sbhd` or `bshd` are supported for input tensor `t` \"\n",
    "        f\"when fused is False, got {tensor_format}.\"\n",
    "    )\n",
    "\n",
    "    max_seq_len = freqs.shape[0]\n",
    "    cur_seq_len = t.shape[1] if tensor_format == \"bshd\" else t.shape[0]\n",
    "\n",
    "    # Only apply the rotary embeddings up to the sequence length of the running\n",
    "    # input.\n",
    "    assert cur_seq_len <= max_seq_len, (\n",
    "        f\"Rotary Embeddings only supported up to {max_seq_len} sequence length!\"\n",
    "    )\n",
    "    freqs = freqs[:cur_seq_len]\n",
    "    if tensor_format == \"bshd\":\n",
    "        freqs = freqs.transpose(0, 1)  # [seq, 1, 1, dim] -> [1, seq, 1, dim]\n",
    "    # cos/sin first then dtype conversion for better precision\n",
    "    cos_ = torch.cos(freqs).to(t.dtype)\n",
    "    sin_ = torch.sin(freqs).to(t.dtype)\n",
    "\n",
    "    rot_dim = freqs.shape[-1]\n",
    "    # ideally t_pass is empty so rotary pos embedding is applied to all tensor t\n",
    "    t, t_pass = t[..., :rot_dim], t[..., rot_dim:]\n",
    "\n",
    "    print('t shape(_rotate_half\\'s input):', t.shape)\n",
    "    # first part is cosine component\n",
    "    # second part is sine component, need to change signs with _rotate_half method\n",
    "    t = (t * cos_) + (_rotate_half(t) * sin_)\n",
    "    return torch.cat((t, t_pass), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b30758",
   "metadata": {},
   "source": [
    "### Prepare input sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43a6977e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s, b, h, d = 10, 2, 4, 16\n",
    "t = torch.randn(s, b, h, d)\n",
    "\n",
    "### hypothsis. s2 = s, d2 = d/2\n",
    "s2, d2 = s, d//2\n",
    "freqs = torch.randn(s2, 1, 1, d2)\n",
    "\n",
    "tensor_format = \"sbhd\"\n",
    "\n",
    "fused = False\n",
    "cu_seqlens = None\n",
    "\n",
    "# t, freqs, tensor_format, fused, cu_seqlens\n",
    "\n",
    "t = t.to('cuda')\n",
    "freqs = freqs.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3718e8",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d99c34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t shape(_rotate_half's input): torch.Size([10, 2, 4, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 2, 4, 16]),\n",
       " tensor(-0.0187, device='cuda:0'),\n",
       " tensor(0.9981, device='cuda:0'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_result = apply_rotary_pos_emb_pytorch(\n",
    "    t=t,\n",
    "    freqs=freqs,\n",
    "    tensor_format=tensor_format,\n",
    ")\n",
    "\n",
    "original_result.shape, original_result.mean(), original_result.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f6799e",
   "metadata": {},
   "source": [
    "- 중간에 _rotate_half 함수가 있는데, apply_rotary_pos_emb_pytorch 함수를 마이그레이션 하기 위해서는 이 또한 변환해야 할 듯 합니다.\n",
    "- 상대적으로 함수가 간단해보여 먼저 시도하였습니다.\n",
    "- 주어진 input에 따른 _rotate_half 함수의 입력 shape로는 (10, 2, 4, 8) 형태가 들어가는 듯 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5e54c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "177f0a7a",
   "metadata": {},
   "source": [
    "# Migrate '_rotate_half' function to triton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb6163d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import triton\n",
    "import triton.language as tl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b04dcc",
   "metadata": {},
   "source": [
    "### Define '_rotate_half_kernel'\n",
    "- 아래 사진에서 3번째 term에 해당하는 (-x2 x2 -x4 x3 ...)을 구현한 것이 '_rotate_half_kernel'인 듯 합니다.\n",
    "- triton은 생소하여 감을 잡는 데에 시간이 많이 걸린 듯 합니다... \n",
    "- 제가 구글링을 잘 못한 탓인지 자료가 많이 없어서 공부하기 어려움이 있었는데, 이 스터디를 통해 꼭 공부해보고 싶습니다.\n",
    "- 총 몇 스레드에서 처리할 지, 한 스레드에서 얼마만큼의 블록을 담당할 지 정하는 부분이 있는데, block size의 경우 그냥 마지막 dimension의 크기로 놓는 경우가 많아 그렇게 했습니다만, 이 또한 좋은 기준이 있을까 궁금합니다\n",
    "- 위에서는 (10, 2, 4, 8) shape이 입력으로 들어가는 것을 확인했으나, 제출용 노트북 파일에서는 그 값을 눈으로도 쉽게 볼 수 있게 하기 위하여 (2,1,2,4) shape을 입력으로 하였습니다. (10, 2, 4, 8)으로 해도 원본 파일과 같은 값을 출력합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d2e714",
   "metadata": {},
   "source": [
    "<img src=\"https://velog.velcdn.com/images/wkshin89/post/e00d46ed-3188-4e9b-bba1-afc908fde31a/image.png\" width=600 height=400 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d4b6e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def _rotate_half_kernel(\n",
    "    output_ptr, input_ptr,\n",
    "    batch_size: tl.constexpr, seq_len: tl.constexpr, head_num: tl.constexpr, d_model: tl.constexpr,\n",
    "    BLOCK_SIZE: tl.constexpr\n",
    "):\n",
    "    idx = tl.program_id(0) * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n",
    "    total_elements = batch_size * seq_len * head_num * d_model\n",
    "    mask = idx < total_elements\n",
    "\n",
    "    dim_idx = idx % d_model\n",
    "    half_dim = d_model // 2\n",
    "    is_second_half = dim_idx >= half_dim\n",
    "\n",
    "    swapped_idx = tl.where(is_second_half, idx - half_dim, idx + half_dim)\n",
    "    data = tl.load(input_ptr + idx, mask=mask)\n",
    "    data_swapped = tl.where(is_second_half, -data, data)\n",
    "\n",
    "    tl.store(output_ptr + swapped_idx, data_swapped, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc216363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6980605",
   "metadata": {},
   "source": [
    "### prepare sample input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c04e9f37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.9488,  0.8871, -1.3509,  0.5680],\n",
       "          [ 0.3531,  0.5859, -0.6028, -1.1586]]],\n",
       "\n",
       "\n",
       "        [[[ 0.6844,  0.4549, -0.4418,  2.3851],\n",
       "          [-0.9007, -0.2924,  0.6402,  1.2308]]]], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2\n",
    "seq_len = 1\n",
    "head_num = 2\n",
    "d_model = 4\n",
    "\n",
    "input_tensor = torch.randn(batch_size, seq_len, head_num, d_model, device='cuda')\n",
    "input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47ad5d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.9488,  0.8871, -1.3509,  0.5680],\n",
       "          [ 0.3531,  0.5859, -0.6028, -1.1586]]],\n",
       "\n",
       "\n",
       "        [[[ 0.6844,  0.4549, -0.4418,  2.3851],\n",
       "          [-0.9007, -0.2924,  0.6402,  1.2308]]]], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = len(input_tensor)\n",
    "stride = input_tensor.stride(0)\n",
    "grid = (length,)\n",
    "BLOCK_SIZE = stride\n",
    "rotated_tensor_triton = torch.empty_like(input_tensor)\n",
    "rotated_tensor_triton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b05e6032",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_elements = batch_size * seq_len * head_num * d_model\n",
    "\n",
    "BLOCK_SIZE = d_model\n",
    "# BLOCK_SIZE = 1\n",
    "grid_size = (total_elements + BLOCK_SIZE - 1) // BLOCK_SIZE\n",
    "# grid_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649428f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e7ddc57",
   "metadata": {},
   "source": [
    "### Compare outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38b11ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated_tensor_pytorch = _rotate_half(input_tensor)\n",
    "\n",
    "_rotate_half_kernel[(grid_size,)](\n",
    "    rotated_tensor_triton, input_tensor, \n",
    "    batch_size=batch_size, seq_len=seq_len, head_num=head_num, d_model=d_model,\n",
    "    BLOCK_SIZE=BLOCK_SIZE\n",
    ")\n",
    "\n",
    "torch.testing.assert_close(rotated_tensor_pytorch, rotated_tensor_triton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d6f0cf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.9488,  0.8871, -1.3509,  0.5680],\n",
       "          [ 0.3531,  0.5859, -0.6028, -1.1586]]],\n",
       "\n",
       "\n",
       "        [[[ 0.6844,  0.4549, -0.4418,  2.3851],\n",
       "          [-0.9007, -0.2924,  0.6402,  1.2308]]]], device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a385d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.3509, -0.5680, -0.9488,  0.8871],\n",
       "          [ 0.6028,  1.1586,  0.3531,  0.5859]]],\n",
       "\n",
       "\n",
       "        [[[ 0.4418, -2.3851,  0.6844,  0.4549],\n",
       "          [-0.6402, -1.2308, -0.9007, -0.2924]]]], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotated_tensor_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57791656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.3509, -0.5680, -0.9488,  0.8871],\n",
       "          [ 0.6028,  1.1586,  0.3531,  0.5859]]],\n",
       "\n",
       "\n",
       "        [[[ 0.4418, -2.3851,  0.6844,  0.4549],\n",
       "          [-0.6402, -1.2308, -0.9007, -0.2924]]]], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotated_tensor_triton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22c20c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3914bd7",
   "metadata": {},
   "source": [
    "### Compare processing time\n",
    "- 몇 줄 되지도 않는 함수고, 그리 어려운 알고리즘도 아니었건만 짜는데 꽤 오래 걸렸는데...\n",
    "- pytorch high level 함수의 조합보다 2배 가까이 느린건 좀 충격입니다.\n",
    "- 일단 정상 동작한다는 점에 의의를 둬야 할 듯 합니다..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77227f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 4.17 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "23.7 µs ± 8.04 µs per loop (mean ± std. dev. of 100 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 100 -r 100 rotated_tensor_pytorch = _rotate_half(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc12e6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.4 µs ± 12 µs per loop (mean ± std. dev. of 100 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 100 -r 100 _rotate_half_kernel[(grid_size,)]( \\\n",
    "    rotated_tensor_triton, input_tensor, \\\n",
    "    batch_size=batch_size, seq_len=seq_len, head_num=head_num, d_model=d_model, \\\n",
    "    BLOCK_SIZE=BLOCK_SIZE \\\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3a81bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
